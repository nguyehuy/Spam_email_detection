# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1roXce7iMIrOJzAZN8vKrRm5jon6BM3Nz
"""

# This class is used for getting the model to predict data
# There are some lines which are commented below, this code is used for 
# determing which algorithsm (svm, RandomForestClassifier, DecisionTreeClassifier, LogisticRegression) is the best for my solution
# I used Kfold to do that . Finally, I got LogisticRegression is the best algorithsm
class model(object):
    def __init__(self):
        pass
    
    def fit (self,X,y):
#         from sklearn import svm
#         from sklearn.ensemble import RandomForestClassifier
#         from sklearn.tree import DecisionTreeClassifier
        from sklearn.model_selection import GridSearchCV
        from sklearn.linear_model import LogisticRegression
        import numpy as np
        import pandas as pd
#         smv_clf=svm.SVC(gamma='scale')
#         smv_clf.fit(X, y)

#         rf_clf=RandomForestClassifier(class_weight='balanced')
#         rf_clf.fit(X, y)

#         dt_clf=DecisionTreeClassifier()
#         dt_clf.fit(X, y)
        
                
#         from sklearn.model_selection import KFold
#         from sklearn.model_selection import cross_val_score
#         k_fold=KFold(n_splits=10,shuffle=True, random_state=0)
        
#         score_rf=np.mean(cross_val_score(rf_clf, X, y, cv=k_fold, n_jobs=1, scoring='accuracy'))
#         score_smv=np.mean(cross_val_score(smv_clf, X, y, cv=k_fold, n_jobs=1, scoring='accuracy'))
#         score_dt=np.mean(cross_val_score(dt_clf, X, y, cv=k_fold, n_jobs=1, scoring='accuracy'))
#         score_lr=np.mean(cross_val_score(lr_clf, X, y, cv=k_fold, n_jobs=1, scoring='accuracy'))
        
#         if score_rf==max(score_rf, score_smv, score_dt, score_lr):
#             print('rf')
#             return rf_clf
#         elif score_smv==max(score_rf, score_smv, score_dt, score_lr):
#             print('smv')
#             return smv_clf
#         elif score_dt==max(score_rf, score_smv, score_dt, score_lr):
#             print('dt')
#             return dt_clf
#         else:
#             print('lr')
#             return lr_clf




        # Using the GridSearch to find out the best parameters 
        lr_clf=LogisticRegression(random_state=0)
        para={'penalty': ['l1', 'l2'],
             'C': [0.01, 0.1, 1, 10, 100]}
        grid_acc=GridSearchCV(lr_clf, param_grid=para, scoring='accuracy')
        grid_acc.fit(X,y)
        mean_score=pd.DataFrame(grid_acc.cv_results_['mean_test_score'].reshape(5,2),
                               columns=['l1', 'l2'], index=['0.01', '0.1', '1', '10', '100'])
        l1_max=mean_score['l1'].max()
        l2_max=mean_score['l2'].max()
        if l1_max>l2_max:
            return grid_acc, 'l1', mean_score['l1'].idxmax()
        else:
            return grid_acc, 'l2', mean_score['l2'].idxmax()

